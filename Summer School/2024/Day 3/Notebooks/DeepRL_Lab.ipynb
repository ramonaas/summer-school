{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "426d8520",
      "metadata": {
        "id": "426d8520"
      },
      "source": [
        "# <center> OpenAI Gym and DQN <center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c5da8a",
      "metadata": {
        "id": "d5c5da8a"
      },
      "source": [
        "### <center> Deep Reinforcement Learning Resource Allocation <center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9032542",
      "metadata": {
        "id": "a9032542"
      },
      "source": [
        "The goal of this notebook is to show how to implement a DQN in the for a resource allocation problem. If you want to know more about DQN, you can read:\n",
        "- [Full gradient DQN reinforcement learning: A provably convergent scheme ](https://arxiv.org/pdf/2103.05981)\n",
        "- Why DQN is bad: [Demystifying Approximate RL with epsilon-greedy Exploration: A Differential Inclusion View ](https://openreview.net/pdf?id=Ms1Zs8s7rg)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c45042a7",
      "metadata": {
        "id": "c45042a7"
      },
      "source": [
        "## Sommaire :\n",
        "\n",
        "* [I. Basic of OpenAI Gym](#1)\n",
        "\n",
        "* [II. Creation of an environment](#2)\n",
        "\n",
        "* [III. Training a DQN Algorithm](#3)\n",
        "\n",
        "* [IV. Exercice](#4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbfce25a",
      "metadata": {
        "id": "bbfce25a"
      },
      "source": [
        "## I. Basic of OpenAI Gym <a class=\"anchor\" id=\"1\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d4df93",
      "metadata": {
        "id": "b1d4df93"
      },
      "source": [
        "Install OpenAi Gym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2533a135",
      "metadata": {
        "scrolled": false,
        "id": "2533a135",
        "outputId": "a4876b59-5e26-42af-d654-30e01ab20264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "pip install gym"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39228dda",
      "metadata": {
        "id": "39228dda"
      },
      "source": [
        "Here a simple test of the environement using the CartPole environement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff34f25",
      "metadata": {
        "id": "3ff34f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660a5a03-e071-4487-be7f-f707da52b5ed",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.03313236  0.01688455 -0.02937806 -0.04279277]\n",
            "[-0.03279467  0.21241519 -0.03023392 -0.34459808]\n",
            "[-0.02854636  0.4079539  -0.03712588 -0.6466595 ]\n",
            "[-0.02038728  0.60357296 -0.05005907 -0.9507984 ]\n",
            "[-0.00831582  0.7993316  -0.06907504 -1.2587798 ]\n",
            "[ 0.00767081  0.60515815 -0.09425063 -0.9885061 ]\n",
            "[ 0.01977397  0.41141573 -0.11402076 -0.7268509 ]\n",
            "[ 0.02800229  0.21803938 -0.12855777 -0.47211942]\n",
            "[ 0.03236307  0.4147204  -0.13800016 -0.8023983 ]\n",
            "[ 0.04065748  0.22173332 -0.15404813 -0.5561132 ]\n",
            "[ 0.04509215  0.41864425 -0.16517039 -0.8930931 ]\n",
            "[ 0.05346503  0.22610116 -0.18303226 -0.65654874]\n",
            "[ 0.05798706  0.42323542 -0.19616322 -1.0008223 ]\n",
            "Episode finished after 13 timesteps\n",
            "[-0.03500262  0.00143521 -0.02950328  0.03343525]\n",
            "[-0.03497391  0.19696756 -0.02883457 -0.26840833]\n",
            "[-0.03103456  0.3924889  -0.03420274 -0.57004464]\n",
            "[-0.02318478  0.5880734  -0.04560363 -0.8733034 ]\n",
            "[-0.01142331  0.7837848  -0.0630697  -1.1799681 ]\n",
            "[ 0.00425238  0.9796663  -0.08666906 -1.4917364 ]\n",
            "[ 0.02384571  1.1757296  -0.11650379 -1.8101763 ]\n",
            "[ 0.0473603   0.98208326 -0.15270731 -1.5558505 ]\n",
            "[ 0.06700196  0.789085   -0.18382433 -1.3144437 ]\n",
            "Episode finished after 9 timesteps\n",
            "[-0.04314347  0.01374816 -0.0075349   0.04348223]\n",
            "[-0.0428685   0.20897734 -0.00666526 -0.25156847]\n",
            "[-0.03868895  0.0139512  -0.01169663  0.03900467]\n",
            "[-0.03840993  0.2092389  -0.01091653 -0.2573456 ]\n",
            "[-0.03422515  0.0142745  -0.01606345  0.03187421]\n",
            "[-0.03393966  0.20962308 -0.01542596 -0.26583332]\n",
            "[-0.0297472   0.40496176 -0.02074263 -0.5633415 ]\n",
            "[-0.02164797  0.21013692 -0.03200946 -0.277265  ]\n",
            "[-0.01744523  0.0154859  -0.03755476  0.00515276]\n",
            "[-0.01713551 -0.1790779  -0.0374517   0.28575417]\n",
            "[-0.02071707  0.01655761 -0.03173662 -0.01850153]\n",
            "[-0.02038592 -0.17809516 -0.03210665  0.2640016 ]\n",
            "[-0.02394782  0.01747    -0.02682662 -0.03863269]\n",
            "[-0.02359842  0.21296616 -0.02759927 -0.33965752]\n",
            "[-0.0193391   0.01824757 -0.03439242 -0.05580401]\n",
            "[-0.01897414  0.21384534 -0.0355085  -0.35913655]\n",
            "[-0.01469724  0.4094536  -0.04269123 -0.66280127]\n",
            "[-0.00650816  0.6051427  -0.05594726 -0.9686149 ]\n",
            "[ 0.00559469  0.4108147  -0.07531956 -0.6940189 ]\n",
            "[ 0.01381098  0.21681389 -0.08919994 -0.42596573]\n",
            "[ 0.01814726  0.4130786  -0.09771925 -0.74538237]\n",
            "[ 0.02640883  0.60940343 -0.1126269  -1.0671486 ]\n",
            "[ 0.0385969   0.80582064 -0.13396987 -1.3929499 ]\n",
            "[ 0.05471332  1.0023316  -0.16182886 -1.7243446 ]\n",
            "[ 0.07475995  1.1988933  -0.19631577 -2.062705  ]\n",
            "Episode finished after 25 timesteps\n",
            "[ 0.041394    0.03676266 -0.00141587  0.04570809]\n",
            "[ 0.04212925  0.2319049  -0.00050171 -0.24742122]\n",
            "[ 0.04676735  0.427034   -0.00545014 -0.54026234]\n",
            "[ 0.05530803  0.23198909 -0.01625538 -0.24930166]\n",
            "[ 0.05994781  0.037103   -0.02124142  0.03820997]\n",
            "[ 0.06068987 -0.157708   -0.02047722  0.32411605]\n",
            "[ 0.05753571  0.03769944 -0.01399489  0.02504646]\n",
            "[ 0.0582897   0.23301926 -0.01349397 -0.27201894]\n",
            "[ 0.06295008  0.42833114 -0.01893434 -0.56892717]\n",
            "[ 0.07151671  0.6237135  -0.03031289 -0.86751455]\n",
            "[ 0.08399098  0.8192345  -0.04766318 -1.169572  ]\n",
            "[ 0.10037567  0.6247638  -0.07105462 -0.8922048 ]\n",
            "[ 0.11287094  0.43067387 -0.08889871 -0.6226771 ]\n",
            "[ 0.12148441  0.23689833 -0.10135226 -0.3592634 ]\n",
            "[ 0.12622239  0.433304   -0.10853752 -0.6821066 ]\n",
            "[ 0.13488847  0.6297525  -0.12217966 -1.0068928 ]\n",
            "[ 0.14748351  0.43645495 -0.14231752 -0.75493944]\n",
            "[ 0.15621261  0.2435517  -0.1574163  -0.5102102 ]\n",
            "[ 0.16108365  0.05095674 -0.16762051 -0.27097923]\n",
            "[ 0.16210279  0.24802452 -0.17304009 -0.61148787]\n",
            "[ 0.16706327  0.05568937 -0.18526985 -0.37791398]\n",
            "[ 0.16817705  0.25289267 -0.19282813 -0.7228149 ]\n",
            "[ 0.17323491  0.06088637 -0.20728442 -0.49648422]\n",
            "Episode finished after 23 timesteps\n",
            "[-0.00646895 -0.02370795 -0.02647789 -0.04282226]\n",
            "[-0.00694311  0.17178348 -0.02733433 -0.34374022]\n",
            "[-0.00350744 -0.02293916 -0.03420914 -0.05980066]\n",
            "[-0.00396622 -0.21755435 -0.03540515  0.2218958 ]\n",
            "[-0.00831731 -0.02194469 -0.03096723 -0.08174174]\n",
            "[-0.0087562  -0.21660936 -0.03260207  0.20101236]\n",
            "[-0.01308839 -0.02103667 -0.02858182 -0.1017741 ]\n",
            "[-0.01350912 -0.2157376  -0.0306173   0.18175608]\n",
            "[-0.01782387 -0.02019121 -0.02698218 -0.12042609]\n",
            "[-0.0182277  -0.2149164  -0.0293907   0.16362357]\n",
            "[-0.02252603 -0.01938631 -0.02611823 -0.13818452]\n",
            "[-0.02291375 -0.21412462 -0.02888192  0.14614543]\n",
            "[-0.02719625 -0.01860123 -0.02595901 -0.15550745]\n",
            "[-0.02756827  0.1768826  -0.02906916 -0.45626548]\n",
            "[-0.02403062  0.37240323 -0.03819447 -0.75796765]\n",
            "[-0.01658255  0.5680301  -0.05335382 -1.0624205 ]\n",
            "[-0.00522195  0.76381636 -0.07460223 -1.3713604 ]\n",
            "[ 0.01005438  0.56970245 -0.10202944 -1.1029122 ]\n",
            "[ 0.02144842  0.76600766 -0.12408768 -1.4257833 ]\n",
            "[ 0.03676858  0.5726184  -0.15260336 -1.1743181 ]\n",
            "[ 0.04822095  0.37977272 -0.17608972 -0.9331027 ]\n",
            "[ 0.0558164   0.18740743 -0.19475177 -0.7005201 ]\n",
            "[ 0.05956455  0.38461924 -0.20876217 -1.0476414 ]\n",
            "Episode finished after 23 timesteps\n",
            "[-0.00353981  0.0265213   0.04436139  0.03254334]\n",
            "[-0.00300938  0.22097994  0.04501225 -0.24581969]\n",
            "[0.00141021 0.02524497 0.04009586 0.06071451]\n",
            "[ 0.00191511 -0.17042825  0.04131015  0.36577347]\n",
            "[-0.00149345 -0.36611217  0.04862562  0.6711906 ]\n",
            "[-0.00881569 -0.17169872  0.06204943  0.39420548]\n",
            "[-0.01224967 -0.36764374  0.06993354  0.7057882 ]\n",
            "[-0.01960254 -0.5636614   0.08404931  1.0196396 ]\n",
            "[-0.03087577 -0.75979674  0.1044421   1.3374856 ]\n",
            "[-0.0460717 -0.9560677  0.1311918  1.6609379]\n",
            "[-0.06519306 -0.7626957   0.16441056  1.4118323 ]\n",
            "[-0.08044697 -0.9594294   0.19264722  1.7510726 ]\n",
            "Episode finished after 12 timesteps\n",
            "[-0.02635034  0.00077264  0.00871739  0.03580571]\n",
            "[-0.02633489 -0.19447322  0.0094335   0.33122626]\n",
            "[-0.03022435 -0.3897282   0.01605803  0.6268691 ]\n",
            "[-0.03801892 -0.19483401  0.02859541  0.33928636]\n",
            "[-0.0419156  -0.39035094  0.03538113  0.64084774]\n",
            "[-0.04972262 -0.5859478   0.04819809  0.9444593 ]\n",
            "[-0.06144157 -0.3915071   0.06708728  0.6673017 ]\n",
            "[-0.06927171 -0.58749473  0.08043331  0.9803307 ]\n",
            "[-0.08102161 -0.3935376   0.10003993  0.71395755]\n",
            "[-0.08889236 -0.19993247  0.11431908  0.45436454]\n",
            "[-0.09289101 -0.00659687  0.12340637  0.19979073]\n",
            "[-0.09302294  0.1865638   0.12740219 -0.05155737]\n",
            "[-0.08929167 -0.0101329   0.12637104  0.2784514 ]\n",
            "[-0.08949433 -0.20680983  0.13194007  0.6081686 ]\n",
            "[-0.09363052 -0.01375522  0.14410344  0.3597815 ]\n",
            "[-0.09390563  0.17905577  0.15129906  0.11578267]\n",
            "[-0.09032451  0.37172255  0.15361471 -0.12560357]\n",
            "[-0.08289006  0.5643483   0.15110265 -0.36615446]\n",
            "[-0.0716031   0.75703627  0.14377956 -0.6076378 ]\n",
            "[-0.05646237  0.94988644  0.1316268  -0.85180247]\n",
            "[-0.03746464  0.7532392   0.11459075 -0.52079666]\n",
            "[-0.02239986  0.5567065   0.10417482 -0.19431491]\n",
            "[-0.01126573  0.750196    0.10028853 -0.45240363]\n",
            "[ 0.00373819  0.94376725  0.09124045 -0.7118662 ]\n",
            "[ 0.02261353  0.7475083   0.07700313 -0.39191478]\n",
            "[ 0.0375637   0.9414578   0.06916483 -0.6593604 ]\n",
            "[ 0.05639286  0.7454449   0.05597762 -0.3457258 ]\n",
            "[ 0.07130176  0.9397278   0.04906311 -0.6202448 ]\n",
            "[ 0.09009631  0.74395615  0.03665821 -0.312522  ]\n",
            "[ 0.10497543  0.5483317   0.03040777 -0.0085073 ]\n",
            "[0.11594207 0.35278714 0.03023762 0.29361242]\n",
            "[0.12299781 0.5474652  0.03610987 0.01061729]\n",
            "[ 0.13394712  0.7420512   0.03632222 -0.27045742]\n",
            "[0.14878814 0.54643023 0.03091307 0.03345684]\n",
            "[0.15971674 0.35087895 0.03158221 0.33573064]\n",
            "[0.16673432 0.54553753 0.03829682 0.053172  ]\n",
            "[ 0.17764507  0.74009     0.03936026 -0.22718625]\n",
            "[0.19244687 0.54442835 0.03481653 0.07764792]\n",
            "[ 0.20333543  0.7390343   0.03636949 -0.20385015]\n",
            "[ 0.21811613  0.9336178   0.03229249 -0.48484206]\n",
            "[ 0.23678848  0.73805535  0.02259565 -0.18215902]\n",
            "[ 0.2515496   0.93284684  0.01895247 -0.46762908]\n",
            "[ 0.27020654  0.7374623   0.00959989 -0.16903324]\n",
            "[ 0.28495577  0.9324455   0.00621922 -0.45867229]\n",
            "[ 0.3036047   1.1274791  -0.00295422 -0.7493884 ]\n",
            "[ 0.32615426  0.93239796 -0.01794199 -0.45763662]\n",
            "[ 0.34480223  1.1277689  -0.02709473 -0.7559205 ]\n",
            "[ 0.3673576   0.93303066 -0.04221313 -0.47188532]\n",
            "[ 0.38601822  0.73852956 -0.05165084 -0.19280055]\n",
            "[ 0.4007888   0.5441831  -0.05550685  0.08315181]\n",
            "[ 0.41167247  0.34989893 -0.05384382  0.35781857]\n",
            "[ 0.41867045  0.15558216 -0.04668745  0.6330489 ]\n",
            "[ 0.42178208  0.35132325 -0.03402647  0.32603607]\n",
            "[ 0.42880854  0.5469127  -0.02750575  0.02281983]\n",
            "[ 0.4397468   0.7424181  -0.02704935 -0.278413  ]\n",
            "[ 0.45459518  0.5476923  -0.03261761  0.00561737]\n",
            "[ 0.46554902  0.35305294 -0.03250526  0.28783324]\n",
            "[ 0.4726101   0.15840924 -0.0267486   0.5700897 ]\n",
            "[ 0.47577825  0.3538959  -0.0153468   0.2691014 ]\n",
            "[ 0.48285618  0.1589963  -0.00996478  0.5569046 ]\n",
            "[0.4860361  0.35425672 0.00117332 0.26109895]\n",
            "[ 0.49312124  0.5493619   0.0063953  -0.03121367]\n",
            "[ 0.5041085   0.74439156  0.00577102 -0.32187197]\n",
            "[ 5.1899630e-01  9.3943083e-01 -6.6641689e-04 -6.1272937e-01]\n",
            "[ 0.53778493  0.74431825 -0.012921   -0.3202564 ]\n",
            "[ 0.5526713   0.5493826  -0.01932613 -0.03167613]\n",
            "[ 0.56365895  0.7447763  -0.01995965 -0.33039346]\n",
            "[ 0.57855445  0.5499441  -0.02656752 -0.04407109]\n",
            "[ 0.58955336  0.7454367  -0.02744895 -0.3450165 ]\n",
            "[ 0.6044621   0.9409382  -0.03434928 -0.6462272 ]\n",
            "[ 0.6232808   0.7463113  -0.04727382 -0.36455572]\n",
            "[ 0.6382071   0.9420721  -0.05456493 -0.6717622 ]\n",
            "[ 0.6570485   0.7477494  -0.06800018 -0.39674613]\n",
            "[ 0.6720035   0.5536548  -0.0759351  -0.12625374]\n",
            "[ 0.6830766   0.74977785 -0.07846018 -0.441894  ]\n",
            "[ 0.69807214  0.9459173  -0.08729806 -0.7582417 ]\n",
            "[ 0.71699053  1.1421268  -0.10246289 -1.0770683 ]\n",
            "[ 0.73983306  0.9484966  -0.12400426 -0.81821764]\n",
            "[ 0.75880295  1.145078   -0.14036861 -1.1471893 ]\n",
            "[ 0.78170455  0.95203954 -0.16331239 -0.9016127 ]\n",
            "[ 0.8007453   0.7594619  -0.18134464 -0.66439044]\n",
            "[ 0.81593454  0.9565811  -0.19463246 -1.0082444 ]\n",
            "Episode finished after 82 timesteps\n",
            "[0.02199163 0.01702288 0.01709549 0.02647893]\n",
            "[ 0.02233208 -0.17834     0.01762507  0.32450628]\n",
            "[ 0.01876528 -0.37370843  0.0241152   0.6226949 ]\n",
            "[ 0.01129111 -0.5691587   0.0365691   0.92287415]\n",
            "[-9.2058544e-05 -7.6475507e-01  5.5026580e-02  1.2268215e+00]\n",
            "[-0.01538716 -0.96054053  0.07956301  1.5362248 ]\n",
            "[-0.03459797 -1.1565251   0.11028751  1.8526386 ]\n",
            "[-0.05772847 -1.3526735   0.14734028  2.1774325 ]\n",
            "[-0.08478194 -1.1592602   0.19088893  1.9336174 ]\n",
            "Episode finished after 9 timesteps\n",
            "[0.02101157 0.01360813 0.0385685  0.040035  ]\n",
            "[ 0.02128373 -0.18204506  0.0393692   0.34463286]\n",
            "[0.01764283 0.01249537 0.04626185 0.06461988]\n",
            "[ 0.01789274 -0.18325828  0.04755425  0.37153232]\n",
            "[ 0.01422757 -0.37902242  0.0549849   0.6788223 ]\n",
            "[ 0.00664713 -0.18470569  0.06856135  0.4039451 ]\n",
            "[0.00295301 0.00938033 0.07664025 0.13364129]\n",
            "[ 0.00314062  0.20332558  0.07931307 -0.13391246]\n",
            "[ 0.00720713  0.39722717  0.07663482 -0.4005569 ]\n",
            "[ 0.01515167  0.20110655  0.06862368 -0.0847308 ]\n",
            "[0.0191738  0.00507144 0.06692907 0.22878928]\n",
            "[ 0.01927523 -0.19093993  0.07150485  0.5418106 ]\n",
            "[ 0.01545643 -0.3869902   0.08234107  0.856139  ]\n",
            "[ 0.00771663 -0.19308098  0.09946384  0.5904415 ]\n",
            "[ 0.00385501 -0.38944456  0.11127268  0.9127253 ]\n",
            "[-0.00393388 -0.19598956  0.12952718  0.65698415]\n",
            "[-0.00785367 -0.39265394  0.14266686  0.98748416]\n",
            "[-0.01570675 -0.58936805  0.16241655  1.3213594 ]\n",
            "[-0.02749411 -0.39662796  0.18884374  1.0835949 ]\n",
            "Episode finished after 19 timesteps\n",
            "[ 0.00490067 -0.0461374  -0.01110018  0.00991567]\n",
            "[ 0.00397792 -0.24109842 -0.01090187  0.29907578]\n",
            "[-0.00084405 -0.4360633  -0.00492035  0.58830065]\n",
            "[-0.00956532 -0.631116    0.00684566  0.8794296 ]\n",
            "[-0.02218764 -0.4360877   0.02443425  0.5889066 ]\n",
            "[-0.03090939 -0.24131629  0.03621238  0.30401963]\n",
            "[-0.03573572 -0.04672861  0.04229277  0.02297361]\n",
            "[-0.03667029  0.1477621   0.04275225 -0.25607124]\n",
            "[-0.03371505  0.3422484   0.03763082 -0.5349688 ]\n",
            "[-0.02687008  0.53682154  0.02693145 -0.815561  ]\n",
            "[-0.01613365  0.7315646   0.01062023 -1.0996528 ]\n",
            "[-0.00150235  0.92654514 -0.01137283 -1.3889848 ]\n",
            "[ 0.01702855  1.121807   -0.03915253 -1.6852021 ]\n",
            "[ 0.03946469  1.3173594  -0.07285657 -1.989814  ]\n",
            "[ 0.06581187  1.5131655  -0.11265285 -2.3041449 ]\n",
            "[ 0.09607518  1.709126   -0.15873574 -2.6292722 ]\n",
            "Episode finished after 16 timesteps\n",
            "[-0.04968008 -0.02887683 -0.03010054 -0.02010907]\n",
            "[-0.05025762  0.16666357 -0.03050272 -0.32213503]\n",
            "[-0.04692434  0.3622063  -0.03694542 -0.6242791 ]\n",
            "[-0.03968022  0.16761911 -0.049431   -0.34345698]\n",
            "[-0.03632784 -0.02676604 -0.05630014 -0.06676219]\n",
            "[-0.03686316 -0.2210375  -0.05763539  0.2076398 ]\n",
            "[-0.04128391 -0.0251408  -0.05348259 -0.10265278]\n",
            "[-0.04178672 -0.2194571  -0.05553564  0.17268854]\n",
            "[-0.04617586 -0.0235861  -0.05208188 -0.1369841 ]\n",
            "[-0.04664759 -0.2179249  -0.05482155  0.13882366]\n",
            "[-0.05100608 -0.02206235 -0.05204508 -0.17063823]\n",
            "[-0.05144733 -0.21640225 -0.05545785  0.10518254]\n",
            "[-0.05577537 -0.4106874  -0.0533542   0.37986597]\n",
            "[-0.06398913 -0.6050127  -0.04575688  0.65526044]\n",
            "[-0.07608937 -0.79946876 -0.03265167  0.93319136]\n",
            "[-0.09207875 -0.60392183 -0.01398784  0.6304295 ]\n",
            "[-0.10415719 -0.7988458  -0.00137925  0.9186746 ]\n",
            "[-0.12013411 -0.6037053   0.01699424  0.6255585 ]\n",
            "[-0.13220821 -0.7990603   0.02950541  0.92354476]\n",
            "[-0.14818941 -0.9945681   0.04797631  1.2253523 ]\n",
            "[-0.16808078 -0.8000956   0.07248335  0.9480788 ]\n",
            "[-0.18408269 -0.99611473  0.09144492  1.2626269 ]\n",
            "[-0.20400499 -0.8022732   0.11669747  0.99992675]\n",
            "[-0.22005045 -0.99874514  0.136696    1.3268615 ]\n",
            "[-0.24002536 -0.80558765  0.16323324  1.0798916 ]\n",
            "[-0.2561371  -0.6129527   0.18483107  0.84255797]\n",
            "[-0.26839617 -0.4207692   0.20168222  0.61322427]\n",
            "Episode finished after 27 timesteps\n",
            "[-0.0307829  -0.01256069 -0.0395919   0.00808794]\n",
            "[-0.03103411 -0.20709313 -0.03943014  0.28802094]\n",
            "[-0.03517598 -0.40163127 -0.03366972  0.5680119 ]\n",
            "[-0.0432086  -0.20605361 -0.02230949  0.26491463]\n",
            "[-0.04732968 -0.40085015 -0.01701119  0.5504783 ]\n",
            "[-0.05534668 -0.5957291  -0.00600163  0.83775336]\n",
            "[-0.06726126 -0.4005257   0.01075344  0.54318905]\n",
            "[-0.07527177 -0.5957971   0.02161722  0.8392407 ]\n",
            "[-0.08718771 -0.4009769   0.03840204  0.5534336 ]\n",
            "[-0.09520725 -0.20641464  0.04947071  0.27309284]\n",
            "[-0.09933554 -0.4022063   0.05493256  0.58095944]\n",
            "[-0.10737967 -0.20789535  0.06655175  0.30607477]\n",
            "[-0.11153758 -0.01378177  0.07267325  0.03510074]\n",
            "[-0.11181322  0.18022685  0.07337526 -0.23379691]\n",
            "[-0.10820868  0.37422788  0.06869932 -0.5024625 ]\n",
            "[-0.10072412  0.17820828  0.05865008 -0.18894492]\n",
            "[-0.09715995  0.37244424  0.05487118 -0.46256468]\n",
            "[-0.08971107  0.17659149  0.04561988 -0.15310365]\n",
            "[-0.08617924 -0.01915298  0.04255781  0.15361516]\n",
            "[-0.0865623  -0.21485764  0.04563011  0.45941457]\n",
            "[-0.09085945 -0.4105939   0.05481841  0.76612395]\n",
            "[-0.09907133 -0.60642606  0.07014088  1.0755395 ]\n",
            "[-0.11119985 -0.4122974   0.09165167  0.805667  ]\n",
            "[-0.1194458  -0.21854332  0.10776501  0.5431636 ]\n",
            "[-0.12381666 -0.4150016   0.11862829  0.8677631 ]\n",
            "[-0.13211669 -0.6115206   0.13598354  1.1952648 ]\n",
            "[-0.1443471  -0.8081155   0.15988885  1.5272909 ]\n",
            "[-0.16050942 -1.0047646   0.19043466  1.8653094 ]\n",
            "Episode finished after 28 timesteps\n",
            "[ 0.03799756  0.03512108 -0.00233333 -0.02336481]\n",
            "[ 0.03869998  0.2302764  -0.00280062 -0.316783  ]\n",
            "[ 0.04330551  0.03519446 -0.00913628 -0.02498462]\n",
            "[ 0.0440094  -0.15979528 -0.00963598  0.26480177]\n",
            "[ 0.04081349  0.03546287 -0.00433994 -0.0309048 ]\n",
            "[ 0.04152275  0.23064679 -0.00495804 -0.32495385]\n",
            "[ 0.04613569  0.42583898 -0.01145711 -0.61919624]\n",
            "[ 0.05465246  0.6211191  -0.02384104 -0.9154654 ]\n",
            "[ 0.06707484  0.8165552  -0.04215035 -1.2155449 ]\n",
            "[ 0.08340595  0.6220015  -0.06646124 -0.9363622 ]\n",
            "[ 0.09584598  0.4278358  -0.08518849 -0.6652818 ]\n",
            "[ 0.1044027   0.23399562 -0.09849413 -0.40059105]\n",
            "[ 0.10908261  0.43036667 -0.10650595 -0.7226305 ]\n",
            "[ 0.11768994  0.62678796 -0.12095855 -1.0468465 ]\n",
            "[ 0.1302257   0.8232894  -0.14189549 -1.3749202 ]\n",
            "[ 0.14669149  1.0198706  -0.1693939  -1.708406  ]\n",
            "[ 0.1670889  1.2164868 -0.203562  -2.048673 ]\n",
            "Episode finished after 17 timesteps\n",
            "[-0.03275526 -0.00940717 -0.04986419  0.046787  ]\n",
            "[-0.03294341 -0.20377995 -0.04892845  0.32332978]\n",
            "[-0.037019   -0.00799667 -0.04246185  0.0156271 ]\n",
            "[-0.03717894 -0.20248476 -0.04214931  0.29461622]\n",
            "[-0.04122863 -0.39698124 -0.03625699  0.5737136 ]\n",
            "[-0.04916826 -0.20137021 -0.02478272  0.2698327 ]\n",
            "[-0.05319566 -0.00590353 -0.01938606 -0.03056267]\n",
            "[-0.05331373  0.18949099 -0.01999732 -0.32929853]\n",
            "[-0.04952391  0.3848918  -0.02658329 -0.62821996]\n",
            "[-0.04182608  0.19015077 -0.03914769 -0.34402618]\n",
            "[-0.03802306  0.38580713 -0.04602821 -0.6487923 ]\n",
            "[-0.03030692  0.58153903 -0.05900405 -0.95560676]\n",
            "[-0.01867614  0.38725823 -0.07811619 -0.68202984]\n",
            "[-0.01093097  0.5833731  -0.09175678 -0.9982479 ]\n",
            "[ 7.3648972e-04  7.7959400e-01 -1.1172175e-01 -1.3182797e+00]\n",
            "[ 0.01632837  0.586048   -0.13808733 -1.0625486 ]\n",
            "[ 0.02804933  0.39299738 -0.15933831 -0.8161979 ]\n",
            "[ 0.03590928  0.5899002  -0.17566226 -1.1544582 ]\n",
            "[ 0.04770728  0.78682256 -0.19875143 -1.4966756 ]\n",
            "Episode finished after 19 timesteps\n",
            "[-0.00223052 -0.04728913 -0.04279422  0.04151933]\n",
            "[-0.0031763  -0.24177213 -0.04196383  0.32039908]\n",
            "[-0.00801175 -0.04607847 -0.03555585  0.01478325]\n",
            "[-0.00893332 -0.24067293 -0.03526019  0.29603925]\n",
            "[-0.01374677 -0.04506652 -0.0293394  -0.00755234]\n",
            "[-0.01464811  0.15046364 -0.02949045 -0.3093459 ]\n",
            "[-0.01163883 -0.04422598 -0.03567737 -0.02610738]\n",
            "[-0.01252335  0.15138896 -0.03619952 -0.32983   ]\n",
            "[-0.00949557 -0.04319948 -0.04279612 -0.04877889]\n",
            "[-0.01035956  0.15250917 -0.0437717  -0.3546513 ]\n",
            "[-0.00730938 -0.04196395 -0.05086472 -0.07608578]\n",
            "[-0.00814866 -0.23632121 -0.05238644  0.20012528]\n",
            "[-0.01287508 -0.43065628 -0.04838393  0.47583345]\n",
            "[-0.02148821 -0.6250628  -0.03886726  0.75288266]\n",
            "[-0.03398946 -0.42942715 -0.02380961  0.44822663]\n",
            "[-0.04257801 -0.23397663 -0.01484508  0.1481346 ]\n",
            "[-0.04725754 -0.4288829  -0.01188238  0.43609747]\n",
            "[-0.0558352  -0.23359476 -0.00316043  0.13969263]\n",
            "[-6.0507093e-02 -4.2867130e-01 -3.6658079e-04  4.3137681e-01]\n",
            "[-0.06908052 -0.23354417  0.00826096  0.13857836]\n",
            "[-0.0737514  -0.0385415   0.01103252 -0.15148696]\n",
            "[-0.07452223  0.15642075  0.00800278 -0.44066903]\n",
            "[-0.07139382  0.35142854 -0.0008106  -0.73081857]\n",
            "[-0.06436525  0.1563178  -0.01542697 -0.43839088]\n",
            "[-0.06123889  0.35165468 -0.02419479 -0.73589665]\n",
            "[-0.0542058   0.54710233 -0.03891272 -1.0360949 ]\n",
            "[-0.04326375  0.35251868 -0.05963462 -0.75587785]\n",
            "[-0.03621338  0.5484097  -0.07475217 -1.0667143 ]\n",
            "[-0.02524518  0.35435212 -0.09608646 -0.7983974 ]\n",
            "[-0.01815814  0.16067049 -0.11205441 -0.5374211 ]\n",
            "[-0.01494473 -0.03271243 -0.12280283 -0.282041  ]\n",
            "[-0.01559898  0.16392764 -0.12844364 -0.6107932 ]\n",
            "[-0.01232043 -0.02918722 -0.14065951 -0.36116576]\n",
            "[-0.01290417 -0.22205886 -0.14788283 -0.11593323]\n",
            "[-0.01734535 -0.41478652 -0.1502015   0.12668364]\n",
            "[-0.02564108 -0.21786769 -0.14766783 -0.20936233]\n",
            "[-0.02999843 -0.41060352 -0.15185507  0.03333835]\n",
            "[-0.0382105  -0.60325855 -0.1511883   0.27452135]\n",
            "[-0.05027568 -0.7959364  -0.14569788  0.515961  ]\n",
            "[-0.0661944  -0.59909564 -0.13537866  0.18114448]\n",
            "[-0.07817632 -0.4023224  -0.13175577 -0.15099463]\n",
            "[-0.08622277 -0.20558406 -0.13477565 -0.4821686 ]\n",
            "[-0.09033445 -0.00884294 -0.14441903 -0.81410825]\n",
            "[-0.09051131  0.18793024 -0.16070119 -1.1485071 ]\n",
            "[-0.0867527  -0.00477141 -0.18367134 -0.910222  ]\n",
            "[-0.08684812  0.19229719 -0.20187578 -1.254549  ]\n",
            "Episode finished after 46 timesteps\n",
            "[ 0.02034829  0.01020091 -0.02185476  0.02057257]\n",
            "[ 0.02055231  0.20562935 -0.02144331 -0.27892488]\n",
            "[ 0.0246649   0.40105054 -0.02702181 -0.5782931 ]\n",
            "[ 0.03268591  0.5965406  -0.03858767 -0.87936455]\n",
            "[ 0.04461672  0.792165   -0.05617496 -1.1839247 ]\n",
            "[ 0.06046002  0.9879689  -0.07985346 -1.493674  ]\n",
            "[ 0.0802194   0.79390407 -0.10972694 -1.2269564 ]\n",
            "[ 0.09609748  0.60035217 -0.13426606 -0.97056955]\n",
            "[ 0.10810452  0.40726286 -0.15367746 -0.72289807]\n",
            "[ 0.11624978  0.6041386  -0.16813542 -1.059735  ]\n",
            "[ 0.12833256  0.8010399  -0.18933012 -1.4001212 ]\n",
            "Episode finished after 11 timesteps\n",
            "[ 0.02972183  0.04136044  0.04618761 -0.0192172 ]\n",
            "[ 0.03054904 -0.15439242  0.04580327  0.28767326]\n",
            "[ 0.02746119 -0.3501366   0.05155673  0.5944431 ]\n",
            "[ 0.02045846 -0.5459408   0.0634456   0.9029101 ]\n",
            "[ 0.00953964 -0.7418622   0.08150379  1.2148414 ]\n",
            "[-0.0052976  -0.93793553  0.10580062  1.5319107 ]\n",
            "[-0.02405632 -1.1341616   0.13643883  1.8556513 ]\n",
            "[-0.04673955 -1.3304935   0.17355186  2.1874008 ]\n",
            "Episode finished after 8 timesteps\n",
            "[-0.02782416 -0.00215019  0.0136537   0.03031634]\n",
            "[-0.02786717 -0.19746526  0.01426003  0.3272757 ]\n",
            "[-0.03181647 -0.3927873   0.02080554  0.62442124]\n",
            "[-0.03967222 -0.1979619   0.03329397  0.3383628 ]\n",
            "[-0.04363146 -0.3935414   0.04006122  0.6413561 ]\n",
            "[-0.05150228 -0.58919823  0.05288835  0.94638073]\n",
            "[-0.06328625 -0.784991    0.07181596  1.2552012 ]\n",
            "[-0.07898607 -0.9809553   0.09691998  1.5694857 ]\n",
            "[-0.09860518 -0.78711486  0.1283097   1.3085395 ]\n",
            "[-0.11434747 -0.9836077   0.15448049  1.6384754 ]\n",
            "[-0.13401963 -1.1801665   0.18725     1.9750395 ]\n",
            "Episode finished after 11 timesteps\n",
            "[-0.02171478 -0.04323593 -0.04566843 -0.03820806]\n",
            "[-0.0225795  -0.23767425 -0.04643259  0.23972349]\n",
            "[-0.02733298 -0.04192081 -0.04163812 -0.06723648]\n",
            "[-0.0281714  -0.23642182 -0.04298285  0.2120241 ]\n",
            "[-0.03289984 -0.4309037  -0.03874237  0.4908444 ]\n",
            "[-0.04151791 -0.62545836 -0.02892548  0.77106994]\n",
            "[-0.05402708 -0.42995054 -0.01350408  0.469428  ]\n",
            "[-0.06262609 -0.6248791  -0.00411552  0.7578242 ]\n",
            "[-0.07512367 -0.81994414  0.01104096  1.0492092 ]\n",
            "[-0.09152255 -1.0152109   0.03202515  1.3453374 ]\n",
            "[-0.11182677 -0.8205059   0.05893189  1.0628436 ]\n",
            "[-0.12823689 -0.6262116   0.08018877  0.78922397]\n",
            "[-0.14076112 -0.82233787  0.09597325  1.1060183 ]\n",
            "[-0.15720788 -1.0185815   0.11809361  1.427202  ]\n",
            "[-0.1775795  -1.2149478   0.14663765  1.7543389 ]\n",
            "[-0.20187846 -1.4113972   0.18172443  2.0888076 ]\n",
            "Episode finished after 16 timesteps\n",
            "[ 0.00189984  0.04468516 -0.01261306  0.01466723]\n",
            "[ 0.00279354  0.2399857  -0.01231972 -0.2819684 ]\n",
            "[ 0.00759325  0.04504162 -0.01795908  0.0068036 ]\n",
            "[ 0.00849408 -0.14981823 -0.01782301  0.29376656]\n",
            "[ 0.00549772  0.04555324 -0.01194768 -0.00448379]\n",
            "[ 0.00640879 -0.14939535 -0.01203736  0.28440568]\n",
            "[ 0.00342088 -0.34434357 -0.00634924  0.57326794]\n",
            "[-0.00346599 -0.5393759   0.00511611  0.8639439 ]\n",
            "[-0.01425351 -0.73456717  0.02239499  1.158231  ]\n",
            "[-0.02894485 -0.5397441   0.04555961  0.8726533 ]\n",
            "[-0.03973974 -0.3452703   0.06301268  0.59463525]\n",
            "[-0.04664514 -0.541215    0.07490538  0.9064824 ]\n",
            "[-0.05746944 -0.3471828   0.09303503  0.63825184]\n",
            "[-0.0644131  -0.54347044  0.10580007  0.95872283]\n",
            "[-0.07528251 -0.34991777  0.12497453  0.70106447]\n",
            "[-0.08228087 -0.5465301   0.13899581  1.0303298 ]\n",
            "[-0.09321146 -0.7432002   0.15960242  1.3632231 ]\n",
            "[-0.10807547 -0.9399207   0.18686688  1.7012777 ]\n",
            "Episode finished after 18 timesteps\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "env = gym.make('CartPole-v0')\n",
        "for i_episode in range(20):\n",
        "    observation = env.reset()\n",
        "    for t in range(100):\n",
        "        #env.render()\n",
        "        print(observation)\n",
        "        action = env.action_space.sample()\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        if done:\n",
        "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "            break\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6a72a9",
      "metadata": {
        "id": "5e6a72a9"
      },
      "source": [
        "\n",
        "The environment is a class implementing the interface of the Gym environment. It is in this class that we will define states, actions, and the <code>step</code> function that is used here. The function <code>step</code> is taking as input an action and will return 4 elements:\n",
        "\n",
        "- An observation : an object specific to our environment that corresponds to the observation obtained from it\n",
        "- A reward\n",
        "- done : indicate whether or not the simulation is over.\n",
        "- info : Extra info to debbug.\n",
        "\n",
        "Please read a bit about the Gym environment by going through this link: https://www.gymlibrary.dev/content/basic_usage/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39055f60",
      "metadata": {
        "id": "39055f60"
      },
      "source": [
        "The action (resp. state) available to the agent are coded in a variable <code>action_space</code> (<code>observation_space</code>.). The classical spaces are <code>Discrete</code> abd <code>Box</code> :\n",
        "\n",
        "- <code>Discrete(n)</code> = {0,1,...,n-1}\n",
        "- <code>Box</code> is a box of size n, with a lower and upper terminal for each dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32c2359",
      "metadata": {
        "id": "e32c2359"
      },
      "source": [
        "The <code>render</code> function is used to display an \"image\" of the environment at time t."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f1b101",
      "metadata": {
        "id": "31f1b101"
      },
      "source": [
        "Here is the shape of the interface corresponding to an OpenAi Gym environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46f7993",
      "metadata": {
        "id": "c46f7993"
      },
      "source": [
        "```\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class CustomEnv(gym.Env):\n",
        "  \"\"\"Custom Environment that follows gym interface\"\"\"\n",
        "  metadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self, arg1, arg2, ...):\n",
        "    super(CustomEnv, self).__init__()    \n",
        "    \n",
        "    # Define action and observation space\n",
        "    # They must be gym.spaces objects    \n",
        "    \n",
        "    # Example when using discrete actions:\n",
        "    self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)    \n",
        "    \n",
        "    # Example for using image as input:\n",
        "    self.observation_space = spaces.Box(low=0, high=255, shape=\n",
        "                    (HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)\n",
        "\n",
        "  def step(self, action):\n",
        "    # Execute one time step within the environment\n",
        "    ...  \n",
        "    \n",
        "  def reset(self):\n",
        "    # Reset the state of the environment to an initial state\n",
        "    ...  \n",
        "    \n",
        "  def render(self, mode='human', close=False):\n",
        "    # Render the environment to the screen\n",
        "    ...\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fe3af9c",
      "metadata": {
        "id": "4fe3af9c"
      },
      "source": [
        "## II. Creation of an environment <a class=\"anchor\" id=\"2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9088156",
      "metadata": {
        "id": "c9088156"
      },
      "source": [
        "#### The machine replacement problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "babefc03",
      "metadata": {
        "id": "babefc03"
      },
      "source": [
        "A machine has possible states in $\\{1,\\ldots,S\\}$ that represent how good it performs (the higher the better), state 1 can be consider as broken, state S as new. At each instant $k=0,\\ldots$ either the machine is replaced (action $a=1$) or it is left unchanged (action $a=2$). We assume that\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{array}{ll}\n",
        "P(s_{k+1}=S|a_k=1) &=1\\\\\n",
        "P(s_{k+1}=s|s_k=s\\_ ,a_k=2) &=(1-\\theta)\\delta_{s\\_ ,s}+\\theta \\delta_{\\max(1,s\\_-1 ),s}.\n",
        "\\end{array}\n",
        "\\end{equation}\n",
        "\n",
        "where $\\delta_{a,b}=1$ if $a=b$ and $0$ otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa676665",
      "metadata": {
        "id": "aa676665"
      },
      "source": [
        "When $a_k = 1$, we replace the machine, and so at next state the machine is new.\n",
        "When $a_k = 2$, we do nothing, and so there is a probability of $1-\\theta$ that we stay at the same state, a probability $\\theta$ that our state decreases of one (the performance of the machine is worse), and if we are already at the worst state, there is a probability of one that we stay at this state."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "420efe51",
      "metadata": {
        "id": "420efe51"
      },
      "source": [
        "At times $k=0,\\ldots$, the cost of machine replacement is $c_k(s,a=1)=C + 1$, while if the machine is not replaced, there is still a cost given by $c_k(s,a=2)=(S-s)/(S-1)+ 1$, due to the loss of quantity/quality of the production of the machine when its state degrades. The discouned cost is given by $\\gamma^kc_k(s,a)$.\n",
        "\n",
        "We add 1 to all costs in order not to have a cost of 0 after repair, because if the cost is 0, as we do not have episodes for this environment, our q-agent won't continue learning (because we train it using a condition on the change of Q-Value and not on the number of iterations)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d143019",
      "metadata": {
        "id": "1d143019"
      },
      "source": [
        "#### Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bbe6951",
      "metadata": {
        "id": "7bbe6951"
      },
      "source": [
        "Download the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce6cf7a6",
      "metadata": {
        "id": "ce6cf7a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9781909-7ad3-4854-aa7e-198170410b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e064fd",
      "metadata": {
        "id": "10e064fd"
      },
      "source": [
        "Machine environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27841337",
      "metadata": {
        "id": "27841337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed98454-7392-4415-bd74-5ca89abf356d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class Machine_env(gym.Env):\n",
        "\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "\n",
        "    def __init__(self, S, θ, C, max_iter = 100):\n",
        "        super(Machine_env, self).__init__()\n",
        "\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "\n",
        "\n",
        "        self.observation_space = spaces.Discrete(S)\n",
        "        self.state = S-1\n",
        "        self.new = S-1\n",
        "        self.p_break = θ\n",
        "        self.cost = C\n",
        "        self.traj = [self.new]\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        # Execute one time step within the environment\n",
        "\n",
        "        if action == 0 :\n",
        "\n",
        "            reward = -((self.new-self.state)/(self.new))\n",
        "\n",
        "            breakdown = st.bernoulli.rvs(self.p_break,size=1)[0]\n",
        "            if breakdown == 1:\n",
        "                if self.state > 0:\n",
        "                    self.state -= 1\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            reward = -self.cost\n",
        "\n",
        "            self.state = self.new\n",
        "\n",
        "\n",
        "        observation = np.array([self.state])\n",
        "        self.traj.append(observation)\n",
        "        done = (len(self.traj)>=self.max_iter)\n",
        "        info = {}\n",
        "\n",
        "        return observation, reward-1, done, info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "    # Reset the state of the environment to an initial state\n",
        "        self.state = self.new\n",
        "        plt.clf()\n",
        "        self.traj = [self.new]\n",
        "        return np.array([self.state])\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "    # Render the environment to the screen\n",
        "        plt.clf()\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Machine State\")\n",
        "        plt.scatter(range(len(self.traj)),self.traj)\n",
        "        plt.show()\n",
        "        plt.pause(0.01)\n",
        "        print(\"State : \", self.state)\n",
        "\n",
        "    def close(self):\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4114447",
      "metadata": {
        "id": "f4114447"
      },
      "source": [
        "## III. Training a DQN Algorithm<a class=\"anchor\" id=\"3\"></a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52300b04",
      "metadata": {
        "id": "52300b04"
      },
      "source": [
        "This code has been inspired by https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required packages"
      ],
      "metadata": {
        "id": "vF33TO1GXbA2"
      },
      "id": "vF33TO1GXbA2"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# start the env\n",
        "S_max = 100\n",
        "env = Machine_env(S_max,0.5,1)"
      ],
      "metadata": {
        "id": "6RxA0abxXaXD"
      },
      "id": "6RxA0abxXaXD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replay Memory\n",
        "\n",
        "We'll be using experience replay memory for training our DQN. It stores\n",
        "the transitions that the agent observes, allowing us to reuse this data\n",
        "later. By sampling from it randomly, the transitions that build up a\n",
        "batch are decorrelated. It has been shown that this greatly stabilizes\n",
        "and improves the DQN training procedure.\n",
        "\n",
        "For this, we're going to need two classses:\n",
        "\n",
        "-  ``Transition`` - a named tuple representing a single transition in\n",
        "   our environment. It essentially maps (state, action) pairs\n",
        "   to their (next_state, reward) result, with the state being the\n",
        "   screen difference image as described later on.\n",
        "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
        "   transitions observed recently. It also implements a ``.sample()``\n",
        "   method for selecting a random batch of transitions for training.\n"
      ],
      "metadata": {
        "id": "FvMp6eesXsWa"
      },
      "id": "FvMp6eesXsWa"
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "JBBVhIMJXtH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8339ab1b-4f4a-465f-c3c0-f354d901ae40"
      },
      "id": "JBBVhIMJXtH5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define our model. But first, let's quickly recap what a DQN is.\n",
        "\n",
        "## DQN algorithm\n",
        "\n",
        "Our aim will be to train a policy that tries to maximize the discounted,\n",
        "cumulative reward\n",
        "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
        "$R_{t_0}$ is also known as the *return*. The discount,\n",
        "$\\gamma$, should be a constant between $0$ and $1$\n",
        "that ensures the sum converges. A lower $\\gamma$ makes\n",
        "rewards from the uncertain far future less important for our agent\n",
        "than the ones in the near future that it can be fairly confident\n",
        "about. It also encourages agents to collect reward closer in time\n",
        "than equivalent rewards that are temporally far away in the future.\n",
        "\n",
        "The main idea behind Q-learning is that if we had a function\n",
        "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
        "us what our return would be, if we were to take an action in a given\n",
        "state, then we could easily construct a policy that maximizes our\n",
        "rewards:\n",
        "\n",
        "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
        "\n",
        "However, we don't know everything about the world, so we don't have\n",
        "access to $Q^*$. But, since neural networks are universal function\n",
        "approximators, we can simply create one and train it to resemble\n",
        "$Q^*$.\n",
        "\n",
        "For our training update rule, we'll use a fact that every $Q$\n",
        "function for some policy obeys the Bellman equation:\n",
        "\n",
        "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
        "\n",
        "The difference between the two sides of the equality is known as the\n",
        "temporal difference error, $\\delta$:\n",
        "\n",
        "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n",
        "\n",
        "To minimise this error, we will use the [Huber\n",
        "loss](https://en.wikipedia.org/wiki/Huber_loss)_. The Huber loss acts\n",
        "like the mean squared error when the error is small, but like the mean\n",
        "absolute error when the error is large - this makes it more robust to\n",
        "outliers when the estimates of $Q$ are very noisy. We calculate\n",
        "this over a batch of transitions, $B$, sampled from the replay\n",
        "memory:\n",
        "\n",
        "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
        "\n",
        "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
        "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
        "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
        "   \\end{cases}\\end{align}\n",
        "\n",
        "### Q-network\n",
        "\n",
        "Our model will be a feed forward  neural network that takes in the\n",
        "difference between the current and previous screen patches. It has two\n",
        "outputs, representing $Q(s, \\mathrm{left})$ and\n",
        "$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n",
        "network). In effect, the network is trying to predict the *expected return* of\n",
        "taking each action given the current input.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5IwmNezAX1xG"
      },
      "id": "5IwmNezAX1xG"
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "lmPO_JwhXwtF"
      },
      "id": "lmPO_JwhXwtF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "### Hyperparameters and utilities\n",
        "This cell instantiates our model and its optimizer, and defines some\n",
        "utilities:\n",
        "\n",
        "-  ``select_action`` - will select an action accordingly to an epsilon\n",
        "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
        "   the action, and sometimes we'll just sample one uniformly. The\n",
        "   probability of choosing a random action will start at ``EPS_START``\n",
        "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
        "   controls the rate of the decay.\n",
        "-  ``plot_durations`` - a helper for plotting the durations of episodes,\n",
        "   along with an average over the last 100 episodes (the measure used in\n",
        "   the official evaluations). The plot will be underneath the cell\n",
        "   containing the main training loop, and will update after every\n",
        "   episode."
      ],
      "metadata": {
        "id": "B1jUy2aZYP-U"
      },
      "id": "B1jUy2aZYP-U"
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the AdamW optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state = env.reset()\n",
        "n_observations = 1\n",
        "\n",
        "policy_net = DQN(1, n_actions).to(device)\n",
        "target_net = DQN(1, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict()) #? copies the weights and biases from policy_net to target_net\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            # print(\"Policy greedy: \", policy_net(state))\n",
        "            # print(\"Policy greedy :\" , policy_net(state).argmax().view(1,1) )\n",
        "            #return torch.argmax(policy_net(state))\n",
        "            return policy_net(state).argmax().view(1,1)\n",
        "\n",
        "    else:\n",
        "      random_action = env.action_space.sample()\n",
        "    #   print(\"Random action: \", random_action)\n",
        "      return torch.tensor([[random_action]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())\n",
        "\n",
        "def plot_trajectory_returns(trajectory_returns, show_result=False):\n",
        "    plt.figure(1)\n",
        "    trajectory_returns_t = torch.tensor(trajectory_returns, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Training Episodes')\n",
        "    plt.ylabel('Trajectory Return')\n",
        "    plt.plot(trajectory_returns_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    # if len(trajectory_returns_t) >= 100:\n",
        "    #     means = trajectory_returns_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "    #     means = torch.cat((torch.zeros(99), means))\n",
        "    #     plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ArRVorUFYJrr",
        "outputId": "198e52e0-ab76-4838-d756-4ca1fee9b8e9"
      },
      "id": "ArRVorUFYJrr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop\n",
        "\n",
        "Finally, the code for training our model.\n",
        "\n",
        "Here, you can find an ``optimize_model`` function that performs a\n",
        "single step of the optimization. It first samples a batch, concatenates\n",
        "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
        "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
        "loss. By definition we set $V(s) = 0$ if $s$ is a terminal\n",
        "state. We also use a target network to compute $V(s_{t+1})$ for\n",
        "added stability. The target network is updated at every step with a\n",
        "[soft update](https://arxiv.org/pdf/1509.02971.pdf)_ controlled by\n",
        "the hyperparameter ``TAU``, which was previously defined.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lo71EkAZa-Yy"
      },
      "id": "Lo71EkAZa-Yy"
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    # print(batch.action)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "PocNlvrIa7XA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599dc357-1adc-40d8-d8ab-61274d1967ce"
      },
      "id": "PocNlvrIa7XA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, you can find the main training loop. At the beginning we reset\n",
        "the environment and obtain the initial ``state`` Tensor. Then, we sample\n",
        "an action, execute it, observe the next state and the reward (always\n",
        "1), and optimize our model once. When the episode ends (our model\n",
        "fails), we restart the loop.\n",
        "\n",
        "Below, `num_episodes` is set to 600 if a GPU is available, otherwise 50\n",
        "episodes are scheduled so training does not take too long. However, 50\n",
        "episodes is insufficient for to observe good performance on cartpole.\n",
        "You should see the model constantly achieve 500 steps within 600 training\n",
        "episodes. Training RL agents can be a noisy process, so restarting training\n",
        "can produce better results if convergence is not observed.\n",
        "\n"
      ],
      "metadata": {
        "id": "hnhpuu20bMDT"
      },
      "id": "hnhpuu20bMDT"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nL0R_J8BHfn",
        "outputId": "464a5dd1-c9b3-420c-8efe-ef1b2530b439"
      },
      "id": "9nL0R_J8BHfn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 150 # 1000\n",
        "\n",
        "trajectory_returns = []\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    traj_return = 0\n",
        "    for t in count():\n",
        "        # print(\"State : \", state)\n",
        "        action = select_action(state)\n",
        "        observation, reward, terminated, info = env.step(action.item())\n",
        "        traj_return = traj_return + (GAMMA ** t ) * reward\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "            # episode_durations.append(t + 1)\n",
        "            # plot_durations()\n",
        "            trajectory_returns.append(traj_return)\n",
        "            plot_trajectory_returns(trajectory_returns)\n",
        "            break\n",
        "\n",
        "print('Complete')\n",
        "# plot_durations(show_result=True)\n",
        "plot_trajectory_returns(trajectory_returns, show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "dlkm-J3xbTn8",
        "outputId": "1fbc1a17-7001-4554-8438-5db10063ccfa"
      },
      "id": "dlkm-J3xbTn8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs_test = torch.tensor([float(i) for i in range(99)])\n",
        "# print(inputs_test)\n",
        "# for i in range(99):\n",
        "#   print(policy_net(torch.tensor(inputs_test[i]))[0])\n",
        "\n",
        "for i in range(99):\n",
        "  Q = policy_net(torch.tensor([float(i)]))\n",
        "  print(Q[0]-Q[1])"
      ],
      "metadata": {
        "id": "MwtME5zUk3lZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7470c9e1-7bd4-43e7-b75f-5c7b23b551ce"
      },
      "id": "MwtME5zUk3lZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.2025, grad_fn=<SubBackward0>)\n",
            "tensor(-1.3708, grad_fn=<SubBackward0>)\n",
            "tensor(-1.5214, grad_fn=<SubBackward0>)\n",
            "tensor(-1.5501, grad_fn=<SubBackward0>)\n",
            "tensor(-1.5431, grad_fn=<SubBackward0>)\n",
            "tensor(-1.5095, grad_fn=<SubBackward0>)\n",
            "tensor(-1.4842, grad_fn=<SubBackward0>)\n",
            "tensor(-1.4606, grad_fn=<SubBackward0>)\n",
            "tensor(-1.4374, grad_fn=<SubBackward0>)\n",
            "tensor(-1.3933, grad_fn=<SubBackward0>)\n",
            "tensor(-1.3399, grad_fn=<SubBackward0>)\n",
            "tensor(-1.2865, grad_fn=<SubBackward0>)\n",
            "tensor(-1.2330, grad_fn=<SubBackward0>)\n",
            "tensor(-1.1796, grad_fn=<SubBackward0>)\n",
            "tensor(-1.1262, grad_fn=<SubBackward0>)\n",
            "tensor(-1.0728, grad_fn=<SubBackward0>)\n",
            "tensor(-1.0192, grad_fn=<SubBackward0>)\n",
            "tensor(-0.9651, grad_fn=<SubBackward0>)\n",
            "tensor(-0.9110, grad_fn=<SubBackward0>)\n",
            "tensor(-0.8569, grad_fn=<SubBackward0>)\n",
            "tensor(-0.8028, grad_fn=<SubBackward0>)\n",
            "tensor(-0.7486, grad_fn=<SubBackward0>)\n",
            "tensor(-0.6912, grad_fn=<SubBackward0>)\n",
            "tensor(-0.6321, grad_fn=<SubBackward0>)\n",
            "tensor(-0.5717, grad_fn=<SubBackward0>)\n",
            "tensor(-0.5099, grad_fn=<SubBackward0>)\n",
            "tensor(-0.4471, grad_fn=<SubBackward0>)\n",
            "tensor(-0.3843, grad_fn=<SubBackward0>)\n",
            "tensor(-0.3217, grad_fn=<SubBackward0>)\n",
            "tensor(-0.2592, grad_fn=<SubBackward0>)\n",
            "tensor(-0.1968, grad_fn=<SubBackward0>)\n",
            "tensor(-0.1343, grad_fn=<SubBackward0>)\n",
            "tensor(-0.0719, grad_fn=<SubBackward0>)\n",
            "tensor(-0.0095, grad_fn=<SubBackward0>)\n",
            "tensor(0.0528, grad_fn=<SubBackward0>)\n",
            "tensor(0.1148, grad_fn=<SubBackward0>)\n",
            "tensor(0.1769, grad_fn=<SubBackward0>)\n",
            "tensor(0.2390, grad_fn=<SubBackward0>)\n",
            "tensor(0.3010, grad_fn=<SubBackward0>)\n",
            "tensor(0.3631, grad_fn=<SubBackward0>)\n",
            "tensor(0.4252, grad_fn=<SubBackward0>)\n",
            "tensor(0.4877, grad_fn=<SubBackward0>)\n",
            "tensor(0.5534, grad_fn=<SubBackward0>)\n",
            "tensor(0.6191, grad_fn=<SubBackward0>)\n",
            "tensor(0.6867, grad_fn=<SubBackward0>)\n",
            "tensor(0.7682, grad_fn=<SubBackward0>)\n",
            "tensor(0.8580, grad_fn=<SubBackward0>)\n",
            "tensor(0.9447, grad_fn=<SubBackward0>)\n",
            "tensor(1.0313, grad_fn=<SubBackward0>)\n",
            "tensor(1.1179, grad_fn=<SubBackward0>)\n",
            "tensor(1.2045, grad_fn=<SubBackward0>)\n",
            "tensor(1.2911, grad_fn=<SubBackward0>)\n",
            "tensor(1.3777, grad_fn=<SubBackward0>)\n",
            "tensor(1.4643, grad_fn=<SubBackward0>)\n",
            "tensor(1.5509, grad_fn=<SubBackward0>)\n",
            "tensor(1.6375, grad_fn=<SubBackward0>)\n",
            "tensor(1.7241, grad_fn=<SubBackward0>)\n",
            "tensor(1.8106, grad_fn=<SubBackward0>)\n",
            "tensor(1.8972, grad_fn=<SubBackward0>)\n",
            "tensor(1.9838, grad_fn=<SubBackward0>)\n",
            "tensor(2.0704, grad_fn=<SubBackward0>)\n",
            "tensor(2.1570, grad_fn=<SubBackward0>)\n",
            "tensor(2.2436, grad_fn=<SubBackward0>)\n",
            "tensor(2.3302, grad_fn=<SubBackward0>)\n",
            "tensor(2.4168, grad_fn=<SubBackward0>)\n",
            "tensor(2.5034, grad_fn=<SubBackward0>)\n",
            "tensor(2.5900, grad_fn=<SubBackward0>)\n",
            "tensor(2.6766, grad_fn=<SubBackward0>)\n",
            "tensor(2.7631, grad_fn=<SubBackward0>)\n",
            "tensor(2.8497, grad_fn=<SubBackward0>)\n",
            "tensor(2.9363, grad_fn=<SubBackward0>)\n",
            "tensor(3.0229, grad_fn=<SubBackward0>)\n",
            "tensor(3.1095, grad_fn=<SubBackward0>)\n",
            "tensor(3.1961, grad_fn=<SubBackward0>)\n",
            "tensor(3.2827, grad_fn=<SubBackward0>)\n",
            "tensor(3.3693, grad_fn=<SubBackward0>)\n",
            "tensor(3.4559, grad_fn=<SubBackward0>)\n",
            "tensor(3.5425, grad_fn=<SubBackward0>)\n",
            "tensor(3.6291, grad_fn=<SubBackward0>)\n",
            "tensor(3.7156, grad_fn=<SubBackward0>)\n",
            "tensor(3.8022, grad_fn=<SubBackward0>)\n",
            "tensor(3.8888, grad_fn=<SubBackward0>)\n",
            "tensor(3.9754, grad_fn=<SubBackward0>)\n",
            "tensor(4.0620, grad_fn=<SubBackward0>)\n",
            "tensor(4.1486, grad_fn=<SubBackward0>)\n",
            "tensor(4.2352, grad_fn=<SubBackward0>)\n",
            "tensor(4.3218, grad_fn=<SubBackward0>)\n",
            "tensor(4.4084, grad_fn=<SubBackward0>)\n",
            "tensor(4.4950, grad_fn=<SubBackward0>)\n",
            "tensor(4.5816, grad_fn=<SubBackward0>)\n",
            "tensor(4.6681, grad_fn=<SubBackward0>)\n",
            "tensor(4.7547, grad_fn=<SubBackward0>)\n",
            "tensor(4.8413, grad_fn=<SubBackward0>)\n",
            "tensor(4.9279, grad_fn=<SubBackward0>)\n",
            "tensor(5.0145, grad_fn=<SubBackward0>)\n",
            "tensor(5.1011, grad_fn=<SubBackward0>)\n",
            "tensor(5.1877, grad_fn=<SubBackward0>)\n",
            "tensor(5.2743, grad_fn=<SubBackward0>)\n",
            "tensor(5.3609, grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation OpenAI Gym : https://www.gymlibrary.dev/content/basic_usage/\n",
        "\n",
        "Part of this lab has been prepared by Pierre Charreaux, Théo Tembou Nzudie during their Project 3A."
      ],
      "metadata": {
        "id": "OSXu8tp9k4Qn"
      },
      "id": "OSXu8tp9k4Qn"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}